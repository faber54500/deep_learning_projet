## <font color=darkred> **DM de Deep Learning** : Classification du Risque Canc√©rologique

###  Introduction et Contexte
* Ce projet s'inscrit dans une d√©marche d'aide au diagnostic pour un cabinet m√©dical.
* Actuellement, le d√©pistage du cancer du sein repose principalement sur l'√¢ge des patientes.
* Cependant, le risque est une donn√©e multifactorielle qui ne peut se limiter √† un seul crit√®re.

**L'objectif de mon mod√®le** est d'√©largir les recommandations de d√©pistage en int√©grant 21 crit√®res biologiques et environnementaux. J'ai utilis√© le jeu de donn√©es `cancer-risk-factors` pour classifier le risque en trois cat√©gories (**Low, Medium, High**).

---

### D√©marche M√©thodologique 

#### 1. Analyse exploratoire des donn√©es 
Pour pr√©parer les donn√©es, j'ai mis en place les √©tapes suivantes :
* J'ai commenc√© par un nettoyage des donn√©es (pr√©sence de doublon, suppression des colonnes inutiles, s√©lection du cancer du sein uniquement ) 
* Exploration des 21 variables (Age, BMI, Smoking, Genetic factors, etc.).
* **Observation cl√©** : J'ai identifi√© un d√©s√©quilibre de classe majeur (19.3% classe "low", 77,8 % de risque "Medium"et 2.8% classe "high").
  
#### 2.  R√©seau de neurones artificiels avec **TensorFlow/Keras**
Normalisation  des donn√©es conception et entra√Ænement d'un r√©seau de neurones s√©quentiel optimis√© pour classifier pr√©cis√©ment les patientes selon leur niveau de risque de cancer.
* **R√©partition  :** r√©partition des groupe pour l'entrainement et le test.
* **Normalisation :** Utilisation du `StandardScaler` pour mettre √† l'√©chelle les variables num√©riques.
* **Encodage :** On transforme les r√©ponses en vecteurs via le One-Hot encoding pour les 3 cat√©gories.
* **Construction et entra√Ænement du r√©seau de neurones** : Initialisation du mod√®le, d√©marrage de l'entra√Ænement.
* **√âvaluation des performances et analyse du mod√®le** : Matrice de confusion, Calcul des m√©triques (Accuracy, Pr√©cision, Recall, F1-score).
* **Conclusion** : Le mod√®le pr√©cis mais aveugle aux cas critiques
* Le mod√®le ne peut pas √™tre d√©ploy√© en l'√©tat car il pr√©sente un risque de s√©curit√© pr√©sence de faux n√©gatifs sur les cas graves.

#### 3. Analyse de l'Influence des Facteurs par matrice de corr√©lation 
G√©n√©ration d'une matrice de corr√©lation et d'une heatmap pour identifier et visualiser les facteurs de risque ayant la plus forte influence statistique sur le niveau de risque de cancer
* **R√©alisation d'une matrice de Corr√©lation** des Facteurs de Risque du Cancer du Sein 
* **Conclusion** : Bien que la matrice de corr√©lation souligne l'influence des facteurs environnementaux (Alcool, Pollution)
* Elle reste un outil limit√©, elle ne d√©tecte pas les interactions complexes

#### 4. Mod√®le avec √©quilibrage des classes par calcul de poids
Application d'une pond√©ration des classes (class_weight) lors du r√©entra√Ænement pour corriger le d√©s√©quilibre des donn√©es et forcer le mod√®le √† accorder plus d'importance aux cat√©gories minoritaires du risque √©lev√©.
* **Calcule automatiquement** des poids, plus une cat√©gorie est petite, plus son poids devient grand.
* **Entra√Ænement** avec les poids calcul√©s.
* **Pr√©diction** √† nouveau sur le jeu de validation
* **√âvaluation des performances et analyse du mod√®le** : Matrice de confusion, Calcul des m√©triques (Accuracy, Pr√©cision, Recall, F1-score).
* **Conclusion** Malgr√© les 91 % de bonnes pr√©dictions, il √©choue √† identifier les urgences vitales.

#### 5. Test de l'√©quilibrage par augmentation de donn√©es synth√©tiques (SMOTE)
Contrairement √† la pond√©ration qui donne plus d'importance aux erreurs, SMOTE agit directement sur la structure du jeu de donn√©es
* **Initialisation de SMOTE** : J'ai configur√© l'algorithme pour √©quilibrer automatiquement les classes de risque en cr√©ant des donn√©es synth√©tiques bas√©es sur les deux plus proches voisins.
* **Application du r√©√©quilibrage** : J'ai appliqu√© SMOTE exclusivement sur mes donn√©es d'entra√Ænement pour corriger le fort d√©s√©quilibre sans biaiser mon jeu de validation.
* **Entra√Ænement optimis√©** : J'ai entra√Æn√© mon mod√®le de Deep Learning sur les donn√©es resampl√©es pour garantir une reconnaissance √©quitable de chaque niveau de risque.
* **Pr√©diction sur les donn√©es** de validation on utilise le mod√®le entra√Æn√© sur les donn√©es SMOTE.
* **√âvaluation des performances et analyse du mod√®le** : Matrice de confusion, Calcul des m√©triques (Accuracy, Pr√©cision, Recall, F1-score).
* **Conclusion** Le mod√®le est toujours performant accuracy 91% , mais il √©choue toujours sur la d√©tection des 2 cas high.

#### 6. Test de l'ajustement du seuil de d√©cision pour la gestion du risque critique
Abaissement du seuil de d√©cision de la classe "High" √† 0.15 pour augmenter la sensibilit√© du mod√®le et garantir une d√©tection des cas les plus critiques.
* **r√©cup√®ration** des scores de confiance pour chaque classe
* **Changement du seuil** pour la classe 'high' qui passe √† 0.15
* **√âvaluation des performances et analyse du mod√®le** : Matrice de confusion, Calcul des m√©triques (Accuracy, Pr√©cision, Recall, F1-score).
* **Conclusion** Malgr√© un ajustement de seuil √† 0.15, le recall pour les patientes high reste √† 0.00.
* Le mod√®le ne remplit pas son r√¥le d'alerte. Cette √©tape d√©montre qu'un seuil de 0.15 est insuffisant.

#### 7. Test du Mod√®le avec un seuil de s√©curit√© optimis√© √† 100% de rappel
Au lieu de laisser le mod√®le choisir la classe la plus probable, m√©thode par d√©faut on force la d√©tection d√®s l'apparition d'un signal faible.
En calant le curseur sur la probabilit√© la plus basse attribu√©e √† une vraie malade (final_threshold).
* **abaissement** du seuil de d√©cision pour ne rater aucun cas de risque √©lev√© (High), m√™me si celui-ci n'est pas majoritaire
* **transformation** des vecteurs complexes en une liste de chiffres simples
* **classement** On regarde si la probabilit√© du risque High (indice 2) atteint ou d√©passe le seuil
* Si le risque de danger n'est pas d√©tect√©, on choisit la classe qui a le score le plus √©lev√© entre Low (0) et Medium (1)
* **√âvaluation des performances et analyse du mod√®le** : Matrice de confusion, Calcul des m√©triques (Accuracy, Pr√©cision, Recall, F1-score).
* **Conclusion** Rappel de 100% sur le risque "High", ce r√©glage permet de d√©tecter la totalit√© des patientes √† haut risque (2 sur 2).


#### 8. Test r√©√©quilibrage SMOTE et optimisation du rappel critique
Couplage du r√©√©quilibrage des donn√©es par SMOTE et de l'ajustement dynamique du seuil de d√©cision pour garantir une d√©tection exhaustive (100% de rappel) des patientes √† haut risque
* **√âquilibrage :** √âquilibrage des donn√©es avec SMOTE, on augmente la repr√©sentation de la classe minoritaire pour aider le neurone
* **Entra√Ænement du mod√®le** Cette m√©thode m'a permis d'obtenir une bien meilleure sensibilit√© sur les classes minoritaires (Low et High).
* **Renvoye des probabilit√©s brutes** pour chaque cat√©gorie (Low, Medium, High)
* **Cr√©ation des probabilit√©s pour la classe 'High'**
* **convertion** au format "One-Hot" (ex: [0, 0, 1]) en un index num√©rique simple (ex: 2)
* **d√©finition** du seuil de d√©cision bas√© sur la probabilit√© la plus basse d'un cas r√©el "High" afin de garantir un rappel de 100% pour la d√©tection des risques critiques.
* **Application du nouveau seuil**
* **√âvaluation des performances et analyse du mod√®le** : Matrice de confusion, Calcul des m√©triques (Accuracy, Pr√©cision, Recall, F1-score).
* **Conclusion** Le mod√®le identifie avec succ√®s les 2 patientes √† risque √©lev√© pr√©sentes dans les donn√©es
    
#### 9.Test √©quilibrage hybride SMOTE-Tomek et Optimisation du Rappel
Couplage de la technique SMOTE-Tomek au calibrage d'un seuil de d√©cision critique pour garantir un rappel de 100% sur l'identification des patientes √† haut risque.
* **√âquilibrage et Nettoyage avec SMOTE-Tomek**
* **Entra√Ænement du mod√®le**
* **s√©lection** de la probabilit√© la plus basse parmi les cas r√©els √† haut risque pour fixer un seuil de s√©curit√© garantissant un rappel de 100 %.
* **# Application du nouveau seuil**
* **√âvaluation des performances et analyse du mod√®le** : Matrice de confusion, Calcul des m√©triques (Accuracy, Pr√©cision, Recall, F1-score).
* **Conclusion** Le mod√®le identifie avec succ√®s les 2 patientes √† risque √©lev√© pr√©sentes dans les donn√©es
Cette approche permet d'am√©liorer la pr√©cision de la classe "High" en passant 0.33 √† 0.40 pour la pr√©cision high






---

### üèÅ Conclusion
Ce travail m'a permis de d√©montrer que la performance d'un projet m√©dical ne repose pas uniquement sur la pr√©cision globale, mais sur la s√©curit√© des pr√©dictions. 

En associant la puissance du **Deep Learning** √† la robustesse d'un **Balanced Random Forest**, **j'ai cr√©√©** une solution fiable. L'ajustement du seuil de d√©cision que **j'ai effectu√©** transforme l'algorithme en un v√©ritable outil de protection, assurant une d√©tection exhaustive des cas critiques pour le cabinet m√©dical.

---

### üìÇ Structure du d√©p√¥t
* `deep_learning.ipynb` : Mon programme complet avec analyses et graphiques.
* `cancer-risk-factors.csv` : Le jeu de donn√©es source.
* `requirements.txt` : Biblioth√®ques n√©cessaires (TensorFlow, Scikit-Learn, Imbalanced-Learn).
