## <font color=darkred> **DM de Deep Learning** : Classification du Risque Canc√©rologique

###  Introduction et Contexte
* Ce projet s'inscrit dans une d√©marche d'aide au diagnostic pour un cabinet m√©dical.
* Actuellement, le d√©pistage du cancer du sein repose principalement sur l'√¢ge des patientes.
* Cependant, le risque est une donn√©e multifactorielle qui ne peut se limiter √† un seul crit√®re.

**L'objectif de mon mod√®le** est d'√©largir les recommandations de d√©pistage en int√©grant 21 crit√®res biologiques et environnementaux. J'ai utilis√© le jeu de donn√©es `cancer-risk-factors` pour classifier le risque en trois cat√©gories (**Low, Medium, High**).

---

### D√©marche M√©thodologique 

#### 1. Analyse exploratoire des donn√©es 
Pour pr√©parer les donn√©es, j'ai mis en place les √©tapes suivantes :
* J'ai commenc√© par un nettoyage des donn√©es (pr√©sence de doublon, suppression des colonnes inutiles, s√©lection du cancer du sein uniquement ) 
* Exploration des 21 variables (Age, BMI, Smoking, Genetic factors, etc.).
* **Observation cl√©** : J'ai identifi√© un d√©s√©quilibre de classe majeur (19.3% classe "low", 77,8 % de risque "Medium"et 2.8% classe "high").
  
#### 2.  R√©seau de neurones artificiels avec **TensorFlow/Keras**
* **R√©partition  :** r√©partition des groupe pour l'entrainement et le test.
* **Normalisation :** Utilisation du `StandardScaler` pour mettre √† l'√©chelle les variables num√©riques.
* **Encodage :** On transforme les r√©ponses en vecteurs via le One-Hot encoding pour les 3 cat√©gories.
* **Construction et entra√Ænement du r√©seau de neurones** : Initialisation du mod√®le, d√©marrage de l'entra√Ænement.
* **√âvaluation des performances et analyse du mod√®le** : Matrice de confusion, Calcul des m√©triques (Accuracy, Pr√©cision, Recall, F1-score).
* **Conclusion** : Le mod√®le pr√©cis mais aveugle aux cas critiques
* Le mod√®le ne peut pas √™tre d√©ploy√© en l'√©tat car il pr√©sente un risque de s√©curit√© pr√©sence de faux n√©gatifs sur les cas graves.

#### 3. Analyse de l'Influence des Facteurs par matrice de corr√©lation 
* **R√©alisation d'une matrice de Corr√©lation** des Facteurs de Risque du Cancer du Sein 
* **Conclusion** : Bien que la matrice de corr√©lation souligne l'influence des facteurs environnementaux (Alcool, Pollution)
* Elle reste un outil limit√©, elle ne d√©tecte pas les interactions complexes

#### 4. Mod√®le avec √©quilibrage des classes par calcul de poids
* **Calcule automatiquement** des poids, plus une cat√©gorie est petite, plus son poids devient grand.
* **Entra√Ænement** avec les poids calcul√©s.
* **Pr√©diction** √† nouveau sur le jeu de validation
* **√âvaluation des performances et analyse du mod√®le** : Matrice de confusion, Calcul des m√©triques (Accuracy, Pr√©cision, Recall, F1-score).
* **Conclusion** Malgr√© les 91 % de bonnes pr√©dictions, il √©choue √† identifier les urgences vitales.

#### 5. Test de l'√©quilibrage par augmentation de donn√©es synth√©tiques (SMOTE)
Contrairement √† la pond√©ration qui donne plus d'importance aux erreurs, SMOTE agit directement sur la structure du jeu de donn√©es
* **Initialisation de SMOTE** : J'ai configur√© l'algorithme pour √©quilibrer automatiquement les classes de risque en cr√©ant des donn√©es synth√©tiques bas√©es sur les deux plus proches voisins.
* **Application du r√©√©quilibrage** : J'ai appliqu√© SMOTE exclusivement sur mes donn√©es d'entra√Ænement pour corriger le fort d√©s√©quilibre sans biaiser mon jeu de validation.
* **Entra√Ænement optimis√©** : J'ai entra√Æn√© mon mod√®le de Deep Learning sur les donn√©es resampl√©es pour garantir une reconnaissance √©quitable de chaque niveau de risque.
* **Pr√©diction sur les donn√©es** de validation on utilise le mod√®le entra√Æn√© sur les donn√©es SMOTE.
* **√âvaluation des performances et analyse du mod√®le** : Matrice de confusion, Calcul des m√©triques (Accuracy, Pr√©cision, Recall, F1-score).
* **Conclusion** Le mod√®le est toujours performant accuracy 91% , mais il √©choue toujours sur la d√©tection des 2 cas high.


#### 6. Test de l'ajustement du seuil de d√©cision pour la gestion du risque critique
Contrairement √† la pond√©ration qui donne plus d'importance aux erreurs, SMOTE agit directement sur la structure du jeu de donn√©es
* **Initialisation de SMOTE** : J'ai configur√© l'algorithme pour √©quilibrer automatiquement les classes de risque en cr√©ant des donn√©es synth√©tiques bas√©es sur les deux plus proches voisins.
* **Application du r√©√©quilibrage** : J'ai appliqu√© SMOTE exclusivement sur mes donn√©es d'entra√Ænement pour corriger le fort d√©s√©quilibre sans biaiser mon jeu de validation.
* **Entra√Ænement optimis√©** : J'ai entra√Æn√© mon mod√®le de Deep Learning sur les donn√©es resampl√©es pour garantir une reconnaissance √©quitable de chaque niveau de risque.
* **Pr√©diction sur les donn√©es** de validation on utilise le mod√®le entra√Æn√© sur les donn√©es SMOTE.
* **√âvaluation des performances et analyse du mod√®le** : Matrice de confusion, Calcul des m√©triques (Accuracy, Pr√©cision, Recall, F1-score).
* **Conclusion** Le mod√®le est toujours performant accuracy 91% , mais il √©choue toujours sur la d√©tection des 2 cas high




#### 3. Architecture du Mod√®le Deep Learning
**J'ai utilis√© un r√©seau de neurones artificiels avec **TensorFlow/Keras** :
* **Structure :** Une architecture multicouche pour extraire les corr√©lations complexes entre les facteurs.
* **R√©gularisation : J'ai int√©gr√© des couches *Dropout* pour √©viter le surapprentissage.

#### 4. Algorithmique d'Ensemble : Balanced Random Forest
J'ai test√© un mod√®le de for√™t al√©atoire √©quilibr√©e :
* **√âquilibrage :** Utilisation d'une strat√©gie de sous-√©chantillonnage pour corriger le biais du dataset.
* Cette m√©thode m'a permis d'obtenir une bien meilleure sensibilit√© sur les classes minoritaires (Low et High).


#### 5. Optimisation de la S√©curit√© M√©dicale
Dans la phase finale, **je me suis concentr√©** sur l'ajustement du seuil de d√©cision :
* **Priorit√© au Rappel :** **J'ai calibr√©** le seuil de probabilit√© pour minimiser les faux n√©gatifs.
* **R√©sultat :** Mon mod√®le atteint un **Rappel (Recall) de 100%** sur la classe "High", garantissant qu'aucun profil √† haut risque ne soit ignor√©.

---

### üèÅ Conclusion
Ce travail m'a permis de d√©montrer que la performance d'un projet m√©dical ne repose pas uniquement sur la pr√©cision globale, mais sur la s√©curit√© des pr√©dictions. 

En associant la puissance du **Deep Learning** √† la robustesse d'un **Balanced Random Forest**, **j'ai cr√©√©** une solution fiable. L'ajustement du seuil de d√©cision que **j'ai effectu√©** transforme l'algorithme en un v√©ritable outil de protection, assurant une d√©tection exhaustive des cas critiques pour le cabinet m√©dical.

---

### üìÇ Structure du d√©p√¥t
* `deep_learning.ipynb` : Mon programme complet avec analyses et graphiques.
* `cancer-risk-factors.csv` : Le jeu de donn√©es source.
* `requirements.txt` : Biblioth√®ques n√©cessaires (TensorFlow, Scikit-Learn, Imbalanced-Learn).
